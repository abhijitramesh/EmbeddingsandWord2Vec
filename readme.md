# Word Embedding
We know that Computers are good with numbers which by association means Neural Networks are good with numbers but not so great with text. In order to do text representation what we usually do in called one-hot encoding where we take a vocabulary and represent it as a vector. Work Embedding means creating a neural network which can learn from a vocabulary of words to represent words as vectors but the catch here is this can also learn some more interesting things like association between words like tenses for example complete and completed. They can also learn gender bases associations like woman and queen or man and king.


